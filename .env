# Gemini Configuration for testing (commented out)
# GEMINI_API_KEY="AIzaSyAIdNAyi6Xmt--DIj3QXy50A4xxnTM_zE8"
# GEMINI_MODEL_ID="gemini-2.5-pro"

# OpenAI Configuration
OPENAI_API_KEY="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"
OPENAI_MODEL_ID="gpt-4o-mini"

# Ollama Configuration (commented out for Gemini testing)
# OLLAMA_AI_MODEL_ID="gemma3:270m"

# For agent with tools (agent.py) - recommended models with tool support
# OLLAMA_AI_MODEL_ID="llama3.1:latest"
# OLLAMA_AI_MODEL_ID="llama3.1:latest"
# OLLAMA_AI_MODEL_ID="deepseek-r1:1.5b"
# OLLAMA_AI_MODEL_ID="qwen2.5:1.5b"

# Optional: Custom Ollama endpoint (default: http://localhost:11434)
# OLLAMA_HOST="http://localhost:11434"

# Model Recommendations:
# - gemma3:270m (273 MB) - Basic chat only, no tool support
# - qwen2.5:0.5b (398 MB) - Lightweight with tool support
# - qwen2.5:1.5b (986 MB) - Balanced performance with tools
# - llama3.2:3b (2.0 GB) - Recommended for agents
# - llama3.1:latest (4.9 GB) - Full-featured with excellent tool support
# - deepseek-r1:1.5b (1.1 GB) - Compact with tool capabilities

# Note: Models marked with tool support are required for agent.py functionality
# Use 'ollama pull <model_name>' to download models before use