# Ollama Configuration
# OLLAMA_AI_MODEL_ID="gemma3:270m"

# For agent with tools (agent.py) - recommended models with tool support
OLLAMA_AI_MODEL_ID="llama3.1:latest"
# OLLAMA_AI_MODEL_ID="llama3.1:latest"
# OLLAMA_AI_MODEL_ID="deepseek-r1:1.5b"
# OLLAMA_AI_MODEL_ID="qwen2.5:1.5b"

# Optional: Custom Ollama endpoint (default: http://localhost:11434)
# OLLAMA_HOST="http://localhost:11434"

# Model Recommendations:
# - gemma3:270m (273 MB) - Basic chat only, no tool support
# - qwen2.5:0.5b (398 MB) - Lightweight with tool support
# - qwen2.5:1.5b (986 MB) - Balanced performance with tools
# - llama3.2:3b (2.0 GB) - Recommended for agents
# - llama3.1:latest (4.9 GB) - Full-featured with excellent tool support
# - deepseek-r1:1.5b (1.1 GB) - Compact with tool capabilities

# Note: Models marked with tool support are required for agent.py functionality
# Use 'ollama pull <model_name>' to download models before use